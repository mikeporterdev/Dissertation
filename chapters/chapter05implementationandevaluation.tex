%!TEX root = ../main.tex
\chapter{Implementation and Evaluation}

%Damien's words not mine
For clarity, we present the implementation and evaluation together and split the presentation by the natural split in the code which is the server and application.

\section{Server}
\subsection{Representational State Transfer (REST)}
To structure the server's web services, I have chosen to use a REST architecture style.
REST involves dividing the web services into specific objects which can be accessed through sending a request to that object's URL, this is called an `endpoint' or a `URI'.
These endpoints are then connected to via different HTTP methods, such as the following:
\begin{description}[align=left]
	\item [GET] Retrieves an item or list of items.
	\item [POST] Creates a new item.
	\item [PUT] Updates an existing item or list of items.
	\item [DELETE] Deletes an item. 
\end{description}
For example, if someone wanted to retrieve all users of a REST service, they could send a GET request to the `/users/' endpoint. 
If, however, they wanted to retrieve a specific user, they would send a GET request to `/users/$x$/' where $x$ is the user's ID.
And finally, sending a POST request to `/users/$x$/quests/' would create a a new quest for user $x$.

Collectively, these request methods and endpoints will form the basis for all communication with the server. 
A full plan for the endpoints of the server artefact can be seen in appendix \ref{appendix:endpoints} and examples of requests in \ref{appendix:requests}.

\subsubsection{JSON}
In order to facilitate communication between the server and devices, JSON has been chosen as the primary messaging format for this system.
JSON is a format of transmitting data in a both human and machine readable way using key value pairs.
When the server is required to return objects from the database, it will be able to serialize the python object into JSON text and return it in the request.
The application will then be able to de-serialize the JSON back into a Java object, translating the JSON values back into object properties.
Examples of possible requests can be seen in appendix \ref{appendix:requests}.

\subsection{Flask}
For the server-side implementation, I will need tools that allow me to easily create a web service API and provide controlled access to functionality over the web.
For this task, I chose to use Flask as it is well established within the Python community and is relatively easy to set up and maintain. 
Flask is suitable for both quick prototyping of web-services and reliable deployment/hosting of the functionality over the internet.

By utilizing Flask, I was able to easily translate a user's web request into a method call, with relevant parameters, using the following code:
\lstinputlisting[language=python]{codesnippets/getrewards.py}
This short code snipped shows the method used to return all rewards in the reward shop for a user.
This method is activated upon sending a GET request to the endpoint such as `server\_host\_name:5000/api/user/1/rewards/', and will return the rewards for the first user in JSON format, provided the attached authentication details match that user. 

\subsection{Database}
\subsubsection{Object-Relational Mapper}
I chose to use a pre-built Object Relational Mapping (ORM) library to interface with the database, rather than crafting particular queries on an ad hoc basis. 
This was primarily for more ease-of-use purposes than any performance reasons. 
I decided upon using SQLAlchemy as the ORM for the server due to strong Flask support.
Specifically, the Flask-SQLAlchemy library was utilized to provide Flask specific functions that could be used to interface with the database.
Implementing an ORM also allows me to more easily protect the application against SQL injection, as Flask purposefully escapes special characters that would allow such an attack \citep[p.15]{copeland2008essential}.

\subsubsection{SQLite}
I have opted to use SQLite to store the user data in the server.
SQLite is a very lightweight RDBMS that is well supported by the Flask-SQLAlchemy library.
The database tables will be automatically generated out of the classes created in Flask on the first run of an application, as well the relationships described in figure \ref{appendix:erd}. 

\subsection{Evaluation}
\subsubsection{Objectives}
Of my objectives, there are two that are relevant to the server.

1. Create a secure and robust public API to allow applications to connect to the the artefact's service.

The server application successfully provides a public API that provides web services to connecting clients.
The server provides the necessary information for clients securely, by requiring successful HTTP authentication to retrieve information about an user or any of it's quests/rewards.
The server is resilient to crashes and automatically rejects bad requests before the invalid data can be stored in the database.

2. Utilize test-driven development to provide automated testing, ensuring test coverage of over 80\% for the API

Using the practice of test-driven development for the server API was a general success. 
For some parts, the methodology was found to be rather strict and caused some delays on development time.
However, once the practice had been used for a little while, it began to drastically improve development time, particularly in the case of debugging that arose during development.
Furthermore, during testing phases, the tested code passed many of its functional tests on the first try, which is likely due to the fact that it is tested during the development process.
Overall, it was found that each particular feature took slightly longer to develop, but took significantly less time during testing phases.
These findings agree with the research in chapter 2, as \cite{IBMTDD} found similar results of reduced productivity, but it resulted in code with less defects.

The final result for automated test coverage came in at 91\% code coverage for the server, exceeding the 80\% target, and analysis of the code shows all major server functions were covered by automated unit tests.

\section{Application}
\subsection{Android}
Android has been chosen for this application due to the large success and market hold of the operating system.
Primarily I will be aiming to support Android versions down to API level 16 (Jelly Bean 4.1).
This decision has been made as appendix \ref{appendix:sdkmarketshare} shows that by supporting this far back, the application will be compatible with over 95\% of current phones. 
Older versions than this will not be targeted, as development and testing time is limited and it would mean that many features would have to be limited due to lacking functionality within these older versions.

\subsection{Google Cloud Messaging}
The app will be responsible for relaying information between the parent and child clients in a reliable and timely manner.
In Android, this can be achieved using push notifications relayed through the Google Cloud Messaging (GCM) service.
GCM can be utilized to send messages to an Android device, but is largely unreliable \citep{gcmreliability} and therefore should only be used for notifications, rather than the transmission of data.
The service requires that the server registers with the GCM to retrieve an API key and that the user device registers to retrieve a GCM registration ID \citep{gcm}. 
When a user registers with the artefact server, the registration ID is stored wtihin the database to be used to send notifications.
When a particular action is performed on an account in the API, the server will check if that user has an attached account - i.e. either a Parent monitoring a Child or vice versa.
Then, the server sends the message and the target GCM registration ID to the GCM system which passes on the message.

Within the application, a listener service has been implemented to be triggered upon the receipt of a GCM message that will create a push notification with the message sent by the server.
Examples of the push notification messages can be seen in appendix \ref{appendix:pushnotifications}.

\section{Game Design}
\subsection{Rewards}
The rate at which these rewards are earned must be examined to ensure they still feel rewarding throughout. 
For example, if a quest returns 100 XP points and you require 300 XP to level up from level 1 to 2, this only requires you to complete three quests to level up, meaning these three quests feel rewarding as each quest is offering 1/3rd of a level.
However, the XP if quests still offer 100 XP and you require 6000 XP to level up from level 30 to 31, the reward from the same quest is now worth 1/60th of a level, despite being the same difficulty to the user.
Therefore, some scaling of the rewards is required in the app to allow XP rewards to scale suitably with the XP required to level.
This scaling is referred to as `increasing cost' \citep{1_anderson_2016}.
Anderson also shows that it is important to determine reasonable caps for numerical relationships in video-games, to stop the increasing cost becoming out of proportion.

\cite{1_anderson_2016} poses that a useful pattern for these kinds of relationships is a classic triangular pattern, in which the first level requires 1 XP to level up, the second level requires 3 XP, the third requires 6. To allow for more meaningful numbers to the user, I have multiplied the results of the formula by 100.

\begin{equation} \label{eq:xprequiredfornextlevel}
	T_n= \frac{n(n+1)}{2} \times 100
\end{equation}

Initially, the scaling formula for XP rewards involved using 60XP as a base reward for a medium difficulty quest, then using the player's current level, it would derive a multiplier that would be used to scale the XP reward.

\begin{equation} \label{eq:xpgainedlinear}
	\textrm{XP Gained} = 60 \times \frac{(n - 1) \times k}{100} + 1
\end{equation}

Where $k$ can be adjusted to specify the strength of the multiplier against the XP rewards, so that if $k$ = 10, a character at level 31 would have a 3x multiplier on quests, meaning the same quest that gave them 60XP at level 1, now gives them 180XP.
However, when modelling this equation, the number of quests completed quickly becomes out of hand. 
At level 1, the player must complete 2 medium quests to level up - a reasonable starting point.
However by level 25 the player must complete 22 quests to level up and by level 99 (One before the level cap) the player must complete an extraordinary 84 medium difficulty quests to level up.

Therefore, triangular numbers can also be useful for calculating the XP gained per quest. By adjusting the triangular numbers formula somewhat, I found a suitable middle ground which still gives the new user the feeling of progressing quickly, but the rate of quests per level quickly slows down to a limit of approximately 10 quests per level by level 100.
This will ensure that the player will still feel like they are progressing at a reasonable speed throughout.

\begin{equation} \label{eq:xpgainedtriangular}
	\textrm{XP Gained} = \frac{(n+2)(n+3)}{2} \times 10
\end{equation}

The rate of quests required to level up using these two systems is mapped in figure \ref{fig:xprewardcomparison}.
This figure was mapped out assuming all quests completed were of medium difficulty, whereas in real usage the speed will increase or decrease depending on the difficulty of quests.

In my evaluation of the artefact, I found that the second system provided much more of a rewarding feel to the user. 
The application still provided a very fast gain when the user first starts using the app, but quickly levels off to a reasonable amount.
Whereas the first system quickly spiralled out of control.

\begin{figure}
\centering
\begin{tikzpicture}
	\begin{axis}[
		xlabel=Level,
		ylabel=Quests to level up,
		xmin=0,
		ymin=0,
		legend pos = outer north east
	]
		\addplot coordinates {
			(1, 1.7)
			(2, 3)
			(3, 4)
			(4, 4.8)
			(5, 5.4)
			(6, 5.9)
			(7, 6.3)
			(8, 6.6)
			(9, 6.9)
			(10,7.1)
			(11,7.3)
			(12,7.5)
			(13,7.6)
			(14,7.8)
			(15,7.9)
			(16,8)
			(17,8.1)
			(18,8.2)
			(19,8.3)
		};
		\addlegendentry{Equation \ref{eq:xpgainedtriangular}}
		\addplot coordinates{
			(1, 1.7)
			(2, 2.5)
			(3, 3.4)
			(4, 4.2)
			(5, 5)
			(6, 5.9)
			(7, 6.7)
			(8, 7.5)
			(9, 8.4)
			(10, 9.2)
			(11, 10)
			(12, 10.9)
			(13, 11.7)
			(14, 12.5)
			(15, 13.4)
			(16, 14.2)
			(17, 15)
			(18, 15.9)
			(19, 16.7)
		};
		\addlegendentry{Equation \ref{eq:xpgainedlinear}}
	\end{axis}
\end{tikzpicture}
\caption{A comparison of two XP reward systems}
\label{fig:xprewardcomparison}
\end{figure}

\subsection{Gold Rewards}
A key goal of the project is achieving long term motivation for children, and to avoid the non-continuous effects mentioned by \cite{deci2001extrinsic} in chapter 2 research.
In order to achieve this goal, I implemented two key elements to the rewards earned from a quest.

Firstly, in order to discourage Child users from delaying performing a task, I implemented a system that gradually diminishes the maximum achievable gold reward for a quest over time. 
In this system, a quest is added with an expiry date value, which defaults to one week from the quest creation date.
At around halfway through the time available to complete the task, the reward from the quest will begin to reduce at a steady rate for the remaining time.
Eventually, if the task remains incomplete until the expiry date, the gold reward drops to zero, the quest expires and the quest is removed from their tasks.
This is an example of an `open loop system', 

Secondly, I extended this system to base the given reward for a quest off of the Child's time-based performance in their last three quests.
This is referred to as a `closed loop system', where the reward amount is calculated based off of previous rewards.
The end result is that if a Child allows a quest to begin expiring, it will effect the following three quests rather than just this one.
This system encourages the user to maintain a streak of fulfilling tasks in a timely manner and discourages them from allowing a quest to expire as it will not just be that reward that is effected, but their rewards for the next three quests.
It is intended that this will influence children to begin thinking about their tasks in a long-term manner.
If the user has completed less than three quests, the effect is ignored as there is not enough data.
The reward is calculated using the following equation:

\begin{equation} \label{eq:closedloopreward}
	y_k = ax_k + by_{k-1} + cy_{k-2} + dy_{k-3}
\end{equation}

A comparison of the two types of rewards can be seen in figure \ref{fig:rewardcomparison}.

\begin{figure}[ht]
\centering
\begin{tikzpicture}
	\begin{axis}[
	xlabel=Quests Completed,
	ylabel=Gold Stored,
	ymin=0,
	xmin=0,
	legend pos = outer north east
	]
		\addplot coordinates{
			(0,0)
			(1,100)
			(2,245)
			(3,495)
			(4,795)
			(5,795)
			(6,1535)
			(7,1585)
			(8,2185)
			(9,2485)
			(10,2485)
			(11,2785)
			(12,2815)
			(13,3115)
			(14,3415)
		};
		\addlegendentry{Open Loop Rewards}
		\addplot coordinates{
			(0,0)
			(1,100)
			(2,245)
			(3,495)
			(4,795)
			(5,795)
			(6,1402)
			(7,1450)
			(8,1891)
			(9,2161)
			(10,2293)
			(11,2496)
			(12,2628)
			(13,2832)
			(14,3098)
		};
		\addlegendentry{Closed Loop Rewards}
	\end{axis}
\end{tikzpicture}
\caption{A comparison of the two reward types}
\label{fig:rewardcomparison}
\end{figure}

The gold and XP reward systems follow two separate paths.
Where both the XP gained per quest and the XP required to level up both increase each level, the gold rewards remain at a continuous gain and do not involve player levels.
Furthermore, with XP, I have preferred the system that rewards the player with more XP, whereas with gold rewards the system that provided less was preferred.
This is mainly due to the inclusion of a reward shop in the project, which exchanges some of the Child's gold storage for a real life reward set by the Parent. 
Therefore, in order for this to work successfully, the amount of gold that a child earns must remain in check.

\subsection{Evaluation}



\section{Testing}
Unfortunately, when developing a REST API, it is difficult to manually write and send the request to the API to test it.
Programs and scripts exist to ease the process somewhat, but I found the easiest way to be automating the requests entirely. 
As a main principle of REST is to plan out the specific endpoints that can be messaged, it becomes rather simple to plan out tests in the form of sending an example of a valid and invalid request of each request type to each endpoint.
For example, the endpoint of `/api/users/<userId>/' allows two request types, GET and PUT, which generates four test cases.
\begin{itemize}
	\item{Valid GET}
	\item{Invalid GET}
	\item{Valid PUT}
	\item{Invalid PUT}
\end{itemize}  
%TODO: Research what test generation this is

However, this raises issues when considering that a request could be invalid for multiple reasons, and simply testing for invalid/valid may not reach adequate code coverage.
An example of this could be that a PUT request may be invalid due to an email address already existing within the database or because they have not included a valid did not include any new data about the user, which are two separate sections of the code that arguably each require their own tests.
This issue is highlighted by \cite{4597151}, who states that testing a program tells us `little about its quality', arguing that the quality of a test case far outweighs sheer quantity of tests.
Because of this, it must be analysed whether or not the test cases achieve sufficient code coverage, rather than just relying on the entry points into the software.
Luckily, the python package `coverage.py' allows for simple analysis of unit tests to determine the current code coverage for tests, which will provide a higher rate of confidence.

\subsection{Test-Driven Development}
In the creation of a REST API, it is much easier to develop a test plan due to the clearly laid out workflow of the user. From the server's point of view, there are only a handful of requests that a user can make, and only a handful of tests for those requests. Before writing each endpoint of the server, I developed a unit test using the Flask-Testing library that would test the various inputs to this end point.
Usually, these unit tests consisted of python code to create and send a request to the testing server and then check the database to verify if the data was stored correctly.

\subsection{Unit Testing} 
As a part of Test-Driven Development, unit testing is a integral part of the development process.

I used an extension library of Flask called Flask-Testing, which streamlined the process of writing and running unit tests.
Flask-Testing allows you to create a new instance of your Flask application with a separate configuration file which can be changed to make the app connect to a different MySQL database file - in this case it connected to a freshly generated and empty test database.
Then, as each separate test case is run, I used the library to delete the test database and regenerate it to ensure that previous unit tests would not interfere with new tests.

For example, the following code is a simple test that creates a child user on the server, then attempts to get the user details from the server without authorizing itself first. 
The test will pass if the server correctly rejects the request with a `401: Not Authorized' error or fail otherwise.
\lstinputlisting[language=python]{codesnippets/serverunittest.py}

\subsection{Integration Testing}
Integration testing encompasses tests that specifically test that the various parts of the project work together correctly.
For example, in this project, integration tests would test that the server and mobile app are able to correctly function together, by ensuring that the app can correctly send requests and that the server receives those requests as they were sent.

As the large majority of functionality took place in the server application, much of the integration testing that took place was to test that the mobile application was correctly requesting, sending and displaying data that it received from the server.


\subsection{Black Box Testing}
Black box testing describes the testing of software without using explicit knowledge of the code.
Essentially, it is testing by using that the usage of the application is correct

\subsection{White Box Testing}


\subsection{Regression Testing}
Regression testing is the practice of retesting the previously tested parts of the software to ensure that they are still performing correctly after a change elsewhere in the code, it can also be used to describe the process of testing previously detected and fixed bugs to determine that they have not reappeared.

This was made significantly easier by the implementation of strong automated unit tests, which allowed me to quickly retest the majority of the code by rerunning the test suite.
I also followed a common development practice where a unit test is added for each defect that is found within the code, a new unit test was added to detect the presence of that bug specifically. 
This allowed me to easily spot any recurrences of legacy bugs that would have otherwise gone unnoticed.

\section{Further Evaluation}
\subsection{Problems Encountered}
\subsubsection{Data Loss}
As predicted in the risk analysis in chapter 1, there was a small issue with data loss during the development of the application.
During a regular reformat of my PC's hard drive, a small amount of code on the machine that had not been saved in a remote location was irretrievably deleted.
However, by following the plans set out in the risk analysis, this issue was greatly mitigated by the fact that I had regularly committed and pushed code to the git repository. 
The lost code was not able to be recovered, but the loss was kept to an absolute minimum as the last commit had taken place only a few hours before the reformat.

\subsubsection{Server Rewrite}
During early design phases, 